# ğŸ¤– Jarbas â€” Assistente IA Local via Terminal

Bem-vindo ao Jarbas!  
Um assistente pessoal com inteligÃªncia artificial, rodando **localmente** no seu computador via linha de comando.

---

## ğŸš€ O que Ã© o Jarbas?

- Conversa com vocÃª pelo terminal (prompt de comando).
- Possui **personalidades** que mudam seu comportamento.
- Guarda o histÃ³rico das conversas para manter o contexto.
- Usa um modelo local (LLaMA3) via API para responder.

---

## ğŸ“‹ Requisitos para rodar

1. **Node.js** (versÃ£o 18 ou superior) instalado no seu computador.  
2. **Modelo LLaMA3 rodando localmente** com API disponÃ­vel em `http://localhost:11434/api/chat`.  
   - Recomendamos usar o [Ollama](https://ollama.com/) para gerenciar o modelo.  
3. Projeto Jarbas clonado com as pastas `personalidades/` e `memoria/`.  
4. Terminal aberto na pasta do projeto para executar os comandos.

---

## âš™ï¸ Como configurar

### 1. Instalar Node.js

- **Windows:** [Baixe aqui](https://nodejs.org/) e instale.  
- **Linux (Debian/Ubuntu):**  
  ```bash
  sudo apt update
  sudo apt install nodejs npm

    Verifique as versÃµes:

    node -v
    npm -v

2. Instalar dependÃªncias do Jarbas

No terminal, dentro da pasta do projeto:

npm install

3. Configurar e iniciar o modelo LLaMA3

    Instale e configure o Ollama seguindo o site oficial.

    Inicie o modelo LLaMA3:

    ollama run llama3

    Certifique-se que a API estÃ¡ rodando em:
    http://localhost:11434/api/chat

ğŸ’¬ Como usar o Jarbas

No terminal, dentro da pasta do projeto:

node index.js

VocÃª verÃ¡ o prompt:

> 

Digite suas perguntas e veja as respostas do Jarbas.
ğŸ”¥ Comandos Ãºteis
Comando	O que faz
!personalidades	Lista as personalidades disponÃ­veis
modo orÃ¡culo	Muda para a personalidade "orÃ¡culo"
modo sentinela	Muda para a personalidade "sentinela"
modo normal	Volta para a personalidade padrÃ£o "jarbas"
!limpar	Limpa a memÃ³ria e histÃ³rico local
!sair	Encerra o Jarbas
ğŸ“‚ Estrutura de arquivos importante

    personalidades/ â€” arquivos .jsonl com personalidades configuradas.

    memoria/memoria.json â€” arquivo com histÃ³rico local salvo.

    historico/ â€” histÃ³rico completo das conversas (perguntas e respostas).

ğŸ›  Dicas e soluÃ§Ã£o de problemas

    Se o Jarbas nÃ£o responder, verifique se o modelo LLaMA3 estÃ¡ rodando na API.

    Sempre rode o Jarbas no terminal dentro da pasta do projeto.

    Para atualizar Node.js ou Ollama, consulte a documentaÃ§Ã£o oficial.

    Caso precise, limpe a memÃ³ria com o comando !limpar.

ğŸ“ Precisa de ajuda?

Fale com o Caverna ou consulte:

    DocumentaÃ§Ã£o Node.js

    Site oficial Ollama

ğŸ© Divirta-se conversando com o Jarbas!
