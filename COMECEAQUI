# 🤖 Jarbas — Assistente IA Local via Terminal

Bem-vindo ao Jarbas!  
Um assistente pessoal com inteligência artificial, rodando **localmente** no seu computador via linha de comando.

---

## 🚀 O que é o Jarbas?

- Conversa com você pelo terminal (prompt de comando).
- Possui **personalidades** que mudam seu comportamento.
- Guarda o histórico das conversas para manter o contexto.
- Usa um modelo local (LLaMA3) via API para responder.

---

## 📋 Requisitos para rodar

1. **Node.js** (versão 18 ou superior) instalado no seu computador.  
2. **Modelo LLaMA3 rodando localmente** com API disponível em `http://localhost:11434/api/chat`.  
   - Recomendamos usar o [Ollama](https://ollama.com/) para gerenciar o modelo.  
3. Projeto Jarbas clonado com as pastas `personalidades/` e `memoria/`.  
4. Terminal aberto na pasta do projeto para executar os comandos.

---

## ⚙️ Como configurar

### 1. Instalar Node.js

- **Windows:** [Baixe aqui](https://nodejs.org/) e instale.  
- **Linux (Debian/Ubuntu):**  
  ```bash
  sudo apt update
  sudo apt install nodejs npm

    Verifique as versões:

    node -v
    npm -v

2. Instalar dependências do Jarbas

No terminal, dentro da pasta do projeto:

npm install

3. Configurar e iniciar o modelo LLaMA3

    Instale e configure o Ollama seguindo o site oficial.

    Inicie o modelo LLaMA3:

    ollama run llama3

    Certifique-se que a API está rodando em:
    http://localhost:11434/api/chat

💬 Como usar o Jarbas

No terminal, dentro da pasta do projeto:

node index.js

Você verá o prompt:

> 

Digite suas perguntas e veja as respostas do Jarbas.
🔥 Comandos úteis
Comando	O que faz
!personalidades	Lista as personalidades disponíveis
modo oráculo	Muda para a personalidade "oráculo"
modo sentinela	Muda para a personalidade "sentinela"
modo normal	Volta para a personalidade padrão "jarbas"
!limpar	Limpa a memória e histórico local
!sair	Encerra o Jarbas
📂 Estrutura de arquivos importante

    personalidades/ — arquivos .jsonl com personalidades configuradas.

    memoria/memoria.json — arquivo com histórico local salvo.

    historico/ — histórico completo das conversas (perguntas e respostas).

🛠 Dicas e solução de problemas

    Se o Jarbas não responder, verifique se o modelo LLaMA3 está rodando na API.

    Sempre rode o Jarbas no terminal dentro da pasta do projeto.

    Para atualizar Node.js ou Ollama, consulte a documentação oficial.

    Caso precise, limpe a memória com o comando !limpar.

📞 Precisa de ajuda?

Fale com o Caverna ou consulte:

    Documentação Node.js

    Site oficial Ollama

🎩 Divirta-se conversando com o Jarbas!
